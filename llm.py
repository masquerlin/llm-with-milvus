import openai
import gradio as gr
from milvus_server import get_data_milvus, update_milvus
pre_prompt = """
# CONTEXT(ä¸Šä¸‹æ–‡) 
æˆ‘æƒ³æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„ç›¸å…³ä¿¡æ¯,ç”¨æˆ·é—®é¢˜çš„å›ç­”
###
# OBJECTIVE(ç›®æ ‡) 
æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œæä¾›çš„ç›¸å…³ä¿¡æ¯, è¿›è¡Œç”¨æˆ·é—®é¢˜çš„å›ç­”

# ATTENTION(æ³¨æ„ç‚¹) 
1ã€å›ç­”å°½é‡åˆ©ç”¨æä¾›çš„ç›¸å…³ä¿¡æ¯
# STYLE(é£æ ¼)
å¹½é»˜ï¼Œè¯¦ç»†ï¼Œç²¾å‡†
###
# TONE(è¯­è°ƒ) 
humorous, professional
###
# AUDIENCE(å—ä¼—) 
æƒ³äº†è§£ç›¸å…³å…³è”ä¿¡æ¯çš„ç”¨æˆ·
###
# RESPONSE(å“åº”) 
å°½é‡åˆ©ç”¨ç›¸å…³å…³è”çš„ä¿¡æ¯æ¥å¯¹ç”¨æˆ·é—®é¢˜è¿›è¡Œå›ç­”

######
ç”¨æˆ·çš„é—®é¢˜: {}

æä¾›çš„ç›¸å…³ä¿¡æ¯: {}

######
Answer:
"""
def run_llm(prompt, history=[], functions=[], sys_prompt= f"You are an useful AI assistant that helps people solve the problem step by step."):

    openai.api_base = "http://localhost:8009/v1"
    openai.api_key = 'none'
    openai.api_request_timeout = 1 # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º10ç§’
    messages=[{"role": "system", "content": sys_prompt}]
    messages.extend(history)
    messages.append({"role": "user", "content": "" + prompt})
    response = openai.ChatCompletion.create(
        model = "qwen_code",
        messages = messages,
        temperature=0.65,
        max_tokens=2048,
        functions=functions
        )
    data_res = response['choices'][0]['message']['content']
    function_call = response['choices'][0]['message']['function_call']
    return data_res, function_call
def model_chat(query, collection_name, history=[]):
    responses = list()
    if len(history) > 0:
        for history_msg in history:
            responses.append(history_msg)
    yield responses
    mylist = list()
    mylist.append(query)
    vector_recall = get_data_milvus(query, collection_name)
    prompt = pre_prompt.format(query, vector_recall)
    answer, functions_call = run_llm(prompt=prompt)
    mylist.append(answer)
    
    
    responses.append(mylist)
    yield responses
def clear_session():
    return '', [], None

def main():
    with gr.Blocks(css="footer {visibility: hidden}",theme=gr.themes.Soft()) as demo:
        gr.Markdown("""<center><font size=10>Code analyze</center>""")
        with gr.Row(equal_height=False):
            file_output = gr.Files(height=200)
            name_box = gr.Textbox()
            output_list = gr.List()
            
        with gr.Row(equal_height=False):
            chatbot = gr.Chatbot(label='æ™ºèƒ½botå›ç­”',scale=1)
        with gr.Row():
            textbox = gr.Textbox(lines=3, label='æå‡ºä½ çš„é—®é¢˜å§')
        with gr.Row():
            with gr.Column():
                clear_history = gr.Button("ğŸ§¹ clear")
                sumbit = gr.Button("ğŸš€ submit")
        file_output.upload(update_milvus, inputs= [file_output, name_box],outputs=[output_list])
        sumbit.click(model_chat, [textbox, name_box, chatbot], [chatbot])
        clear_history.click(fn=clear_session,
                            inputs=[],
                            outputs=[textbox, chatbot])
    demo.queue(api_open=False).launch(server_name='localhost', server_port=7860,max_threads=10, height=800, share=False)
if __name__ == "__main__":
    main()